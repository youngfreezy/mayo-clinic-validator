---
title: Mayo Clinic Content Validator
emoji: ğŸ¥
colorFrom: blue
colorTo: indigo
sdk: docker
pinned: false
---

# Mayo Clinic Content Validator

A multi-agent LangGraph content validation platform with human-in-the-loop (HITL) approval. Input any Mayo Clinic URL and get automated compliance, editorial, and medical accuracy validation with real-time SSE updates and a Next.js review dashboard.

---

## Architecture Overview

### LangGraph Pipeline

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚          LANGGRAPH STATE MACHINE            â”‚
                        â”‚  (PostgresCheckpointer â€” durable HITL)      â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                          â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    fetch_content_node  â”‚
                              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                              â”‚  â”‚  Web Scraper     â”‚  â”‚
                              â”‚  â”‚ (httpx + BS4)    â”‚  â”‚
                              â”‚  â”‚                  â”‚  â”‚
                              â”‚  â”‚ Extracts:        â”‚  â”‚
                              â”‚  â”‚ â€¢ Title          â”‚  â”‚
                              â”‚  â”‚ â€¢ Meta tags      â”‚  â”‚
                              â”‚  â”‚ â€¢ JSON-LD        â”‚  â”‚
                              â”‚  â”‚ â€¢ Body text      â”‚  â”‚
                              â”‚  â”‚ â€¢ Headings       â”‚  â”‚
                              â”‚  â”‚ â€¢ Last reviewed  â”‚  â”‚
                              â”‚  â”‚ â€¢ OG tags        â”‚  â”‚
                              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚      triage_node       â”‚
                              â”‚  URL-based router      â”‚
                              â”‚  HIL â†’ 5 agents        â”‚
                              â”‚  Standard â†’ 4 agents   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                              dispatch_agents() â€” Send API
                              (conditional based on routing_decision)
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          â”‚           â”‚           â”‚              â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ metadata   â”‚ â”‚editorial â”‚ â”‚complianceâ”‚ â”‚accuracy     â”‚ â”‚empty_tag   â”‚
          â”‚ _node      â”‚ â”‚_node     â”‚ â”‚_node     â”‚ â”‚_node        â”‚ â”‚_node       â”‚
          â”‚            â”‚ â”‚          â”‚ â”‚          â”‚ â”‚             â”‚ â”‚(HIL only)  â”‚
          â”‚  GPT-4o    â”‚ â”‚ GPT-4o   â”‚ â”‚ GPT-4o   â”‚ â”‚ PGVector RAGâ”‚ â”‚ Regex scan â”‚
          â”‚            â”‚ â”‚          â”‚ â”‚          â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚ raw HTML   â”‚
          â”‚ â€¢ Meta descâ”‚ â”‚ â€¢ H1-H4  â”‚ â”‚ â€¢ No     â”‚ â”‚ MMR k=5    â”‚ â”‚            â”‚
          â”‚ â€¢ Canonicalâ”‚ â”‚ â€¢ Review â”‚ â”‚  "cures" â”‚ â”‚ GPT-4o     â”‚ â”‚ â€¢ <title/> â”‚
          â”‚ â€¢ JSON-LD  â”‚ â”‚ â€¢ Attribâ”‚ â”‚ â€¢ Discl. â”‚ â”‚ fact-check â”‚ â”‚ â€¢ <h1/>    â”‚
          â”‚ â€¢ OG tags  â”‚ â”‚ â€¢ Sect. â”‚ â”‚ â€¢ FDA    â”‚ â”‚ vs refs    â”‚ â”‚ â€¢ <p/>     â”‚
          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚            â”‚            â”‚              â”‚    (cond.)   â”‚
                findings (Annotated[List, operator.add] reducer)
                                        â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   aggregate_node   â”‚
                              â”‚ overall_score =    â”‚
                              â”‚ mean(all scores)   â”‚
                              â”‚ overall_passed =   â”‚
                              â”‚ all(passed)        â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    judge_node      â”‚
                              â”‚ LLM-as-a-Judge     â”‚
                              â”‚ (GPT-4o-mini)      â”‚
                              â”‚ â†’ approve/reject/  â”‚
                              â”‚   needs_revision   â”‚
                              â”‚ â†’ confidence level â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  human_gate_node   â”‚
                              â”‚                    â”‚
                              â”‚  interrupt()  â—„â”€â”€â”€â”€â”¼â”€â”€â”€â”€ SSE: {type:"hitl"}
                              â”‚  judge rec shown   â”‚         graph suspends
                              â”‚  to reviewer       â”‚         state persisted
                              â”‚  PostgresChkpt     â”‚
                              â”‚  checkpoints here  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚ Command(resume={decision, feedback})
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚                          â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
               â”‚  approve_node   â”‚       â”‚   reject_node   â”‚
               â”‚  status=approvedâ”‚       â”‚  status=rejectedâ”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                          â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   END
                           SSE: {type:"done"}
```

### SSE Event Flow (Client â†” Server)

```
Browser                         FastAPI Backend                    LangGraph
   â”‚                                  â”‚                               â”‚
   â”‚â”€â”€â”€ POST /api/validate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                               â”‚
   â”‚â—„â”€â”€ {validation_id: "abc-123"} â”€â”€â”€â”‚                               â”‚
   â”‚                                  â”‚                               â”‚
   â”‚â”€â”€â”€ GET /api/validate/abc/stream â–ºâ”‚ (SSE connection stays open)   â”‚
   â”‚                                  â”‚â”€â”€â”€â”€ astream(initial_state) â”€â”€â–ºâ”‚
   â”‚â—„â”€â”€ data:{type:"status",          â”‚                               â”‚ fetch_content
   â”‚         data:{status:"scraping"}}â”‚â—„â”€â”€ chunk: status=running â”€â”€â”€â”€â”€â”‚ done
   â”‚â—„â”€â”€ data:{type:"status",          â”‚                               â”‚
   â”‚         data:{status:"running"}} â”‚                               â”‚ 4 parallel
   â”‚                                  â”‚                               â”‚ agents run
   â”‚â—„â”€â”€ data:{type:"agent_complete",  â”‚â—„â”€â”€ chunk: findings=[...] â”€â”€â”€â”€â”€â”‚ all done
   â”‚         data:{agent:"metadata"}} â”‚                               â”‚
   â”‚â—„â”€â”€ data:{type:"agent_complete",  â”‚                               â”‚ aggregate
   â”‚         data:{agent:"editorial"}}â”‚                               â”‚ node
   â”‚â—„â”€â”€ data:{type:"agent_complete",  â”‚                               â”‚
   â”‚         data:{agent:"compliance"}}                               â”‚
   â”‚â—„â”€â”€ data:{type:"agent_complete",  â”‚â—„â”€â”€ chunk: status=            â”‚ human_gate
   â”‚         data:{agent:"accuracy"}} â”‚     awaiting_human â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ interrupt()
   â”‚â—„â”€â”€ data:{type:"hitl",            â”‚     (graph frozen)            â”‚
   â”‚         data:{overall_score,...}}â”‚                               â”‚
   â”‚                                  â”‚   [EventSource stays open â€” no "done" yet]
   â”‚                                  â”‚                               â”‚
   â”‚â”€â”€â”€ POST /api/validate/abc/decideâ–ºâ”‚                               â”‚
   â”‚    {decision:"approve",...}      â”‚â”€â”€ astream(Command(resume=)) â”€â–ºâ”‚
   â”‚                                  â”‚                               â”‚ human_gate
   â”‚                                  â”‚â—„â”€â”€ chunk: status=approved â”€â”€â”€â”€â”‚ resumes
   â”‚â—„â”€â”€ data:{type:"done",            â”‚                               â”‚ â†’ approve
   â”‚         data:{status:"approved"}}â”‚                               â”‚ node â†’ END
   â”‚   (EventSource closes)           â”‚                               â”‚
```

### Web Scraper

The **web scraper** (`backend/tools/web_scraper.py`) uses `httpx` + `BeautifulSoup4` to parse server-side rendered HTML from Mayo Clinic pages. It extracts:

| Data Point | HTML Target |
|------------|-------------|
| Title | `<h1>` â†’ fallback `<title>` |
| Meta description | `<meta name="description">` |
| Canonical URL | `<link rel="canonical">` |
| JSON-LD structured data | `<script type="application/ld+json">` |
| Open Graph tags | `<meta property="og:*">` |
| Body text | `#main-content` â†’ `<main>` â†’ `<article>` cascade |
| Last reviewed date | Text containing "Updated by Mayo Clinic Staff" |
| Heading hierarchy | All `<h1>`â€“`<h4>` within main content |
| Internal links | `href` starting with `/` or `mayoclinic.org` |
| External links | Other `http` hrefs |

> **Note:** Mayo Clinic pages are server-side rendered. A real browser `User-Agent` header is required (included in the scraper) â€” without it you receive a 403.

### RAG Knowledge Base (PGVector)

The **accuracy agent** uses Retrieval-Augmented Generation:

```
Content body text
       â”‚
       â–¼
OpenAI text-embedding-3-small
       â”‚
       â–¼
PGVector MMR Search (k=5, fetch_k=20)
       â”‚
       â–¼
Retrieved Mayo medical reference chunks
       â”‚ (diabetes, hypertension, heart disease,
       â”‚  cancer screening, mental health, COVID-19,
       â”‚  Mayo editorial standards)
       â–¼
GPT-4o fact-checks content claims vs references
       â”‚
       â–¼
AgentFinding {passed, score, issues, recommendations}
```

### State Design (LangGraph TypedDict + Annotated Reducers)

```python
class ValidationState(TypedDict):
    findings: Annotated[List[AgentFinding], operator.add]   # merge all dispatched agents
    agent_statuses: Annotated[Dict[str, str], _merge_dicts] # merge dict keys
    errors: Annotated[List[str], operator.add]               # accumulate errors
    messages: Annotated[List[BaseMessage], add_messages]     # LangChain messages
    # ... plus status, url, scraped_content, overall_score, HITL fields
```

The `Annotated` reducers are **mandatory** for the `Send` API parallel fan-out. Without them, only one agent's findings would survive (last-write-wins).

---

## Stack

| Layer | Technology |
|-------|-----------|
| Orchestration | LangGraph 1.0 (StateGraph, Send API, interrupt/Command, PostgresCheckpointer) |
| LLM | OpenAI GPT-4o (agents) + GPT-4o-mini (judge) |
| Vector DB | PostgreSQL 16 + pgvector (Docker) |
| Embeddings | OpenAI text-embedding-3-small |
| Web Scraping | httpx + BeautifulSoup4 + lxml |
| API | FastAPI + uvicorn + sse-starlette |
| Frontend | Next.js 14 App Router + TypeScript + Tailwind CSS |
| Observability | LangSmith (tracing, per-agent tags, trace URL correlation) |
| Checkpointer | AsyncPostgresSaver (durable HITL state, survives restarts) |
| Testing | pytest + Playwright |
| Runtime | Python 3.11 + Node 20 |

---

## Quick Start

### Prerequisites
- **Docker Desktop** â€” running before anything else
- **Python 3.11** â€” install with `brew install python@3.11` (available at `/opt/homebrew/bin/python3.11`)
- **Node 20** â€” install with `brew install node@20` (available at `/opt/homebrew/opt/node@20/bin/node`)
- **OpenAI API key** â€” already set in `backend/.env`

> **Ports used:** PostgreSQL on `5433`, FastAPI on `8000`, Next.js on `3000`.

---

### Step 1 â€” Database (one-time setup)

```bash
cd backend

# Start PostgreSQL + pgvector container on port 5433
docker compose up -d

# Create virtualenv with Python 3.11
/opt/homebrew/bin/python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Seed the RAG knowledge base (calls OpenAI Embeddings â€” run once)
python scripts/seed_knowledge.py
```

### Step 2 â€” Backend (Terminal 1)

```bash
cd backend
source venv/bin/activate          # activate the Python 3.11 venv
uvicorn main:app --host 0.0.0.0 --port 8000

# Verify: http://localhost:8000/api/health â†’ {"status":"ok"}
```

> **Note:** HITL state is persisted to Postgres via `AsyncPostgresSaver`. You can safely restart uvicorn without losing pending reviews.

### Step 3 â€” Frontend (Terminal 2)

```bash
cd frontend
export PATH="/opt/homebrew/opt/node@20/bin:$PATH"   # use Node 20
npm install          # first time only
npm run dev
# â†’ http://localhost:3000
```

### Step 4 â€” Validate on the UI

1. Open **http://localhost:3000**
2. Paste any `mayoclinic.org` URL (e.g. `https://www.mayoclinic.org/diseases-conditions/diabetes/symptoms-causes/syc-20371444`)
3. Click **Validate**
4. Watch agents complete in real time (4-5 agents depending on URL, plus LLM Judge)
5. Review the Judge's recommendation, then click **Approve** or **Reject** in the Human Review panel

Validation history is persisted to Postgres and survives backend restarts.

---

### Run Tests

```bash
# Backend unit tests (no network calls, no OpenAI)
cd backend
source venv/bin/activate
/opt/homebrew/bin/python3.11 -m pytest tests/test_scraper.py tests/test_schemas.py -v

# Frontend Playwright E2E tests (requires both servers running on 8000 + 3000)
cd frontend
PATH="/opt/homebrew/opt/node@20/bin:$PATH" npx playwright test
```

---

## Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/api/validate` | Submit Mayo Clinic URL |
| `GET` | `/api/validate/{id}/stream` | SSE stream of live progress |
| `GET` | `/api/validate/{id}` | Get current validation state |
| `POST` | `/api/validate/{id}/decide` | Human approve/reject (HITL) |
| `GET` | `/api/validations` | List recent validations |
| `GET` | `/api/health` | Health check |

---

## Validation Agents

| Agent | Checks | Pass Threshold | Routing |
|-------|--------|---------------|---------|
| **Metadata** | Meta description length (150-160 chars), canonical URL, JSON-LD schema type, OG tags | â‰¥ 0.7 | Always |
| **Editorial** | H1-H4 hierarchy, last reviewed date (â‰¤2 years), Mayo attribution, required sections | â‰¥ 0.7 | Always |
| **Compliance** | No absolute claims ("cures"), required disclaimers, FDA language, HIPAA concerns, hedging | â‰¥ 0.75 | Always |
| **Accuracy** | Medical fact-checking vs PGVector knowledge base (RAG) | â‰¥ 0.75 | Always |
| **Empty Tag** | Self-closing/empty HTML tags (`<title/>`, `<h1></h1>`, etc.) | â‰¥ 0.8 | HIL only |
| **Judge** | LLM-as-a-Judge meta-evaluator â€” synthesizes all findings into recommendation | N/A | Always |

Overall pass = **all dispatched agents pass**. Overall score = **mean of agent scores**. Judge provides recommendation to human reviewer.

---

## HITL + PostgresCheckpointer

Human gate uses LangGraph's `interrupt()` + `Command(resume=...)` pattern:
- Graph pauses at `human_gate_node`, state persisted in `AsyncPostgresSaver` (Postgres)
- SSE stream stays open (no `done` event)
- `POST /api/validate/{id}/decide` resumes graph via `Command(resume={decision})`
- `interrupt()` returns the decision dict â€” node routes to approve/reject

**How the checkpointer works:**

| Event | What happens |
|-------|-------------|
| Every graph node completes | Checkpointer serializes full `ValidationState` to Postgres (keyed by `thread_id`) |
| `interrupt()` called in `human_gate_node` | Graph suspends â€” checkpointer saves exact execution position |
| Human submits decision | `astream(Command(resume=...))` reloads saved state from Postgres and resumes from where it paused |
| Server restarts while awaiting review | Pending HITL validations survive â€” state is durable in Postgres |

> Falls back to in-memory `MemorySaver` when Postgres is unavailable (e.g., local development without Docker).

## Conditional Routing (Content Triage)

The `triage_node` classifies URLs before agent dispatch:

| URL Pattern | Content Type | Agents Dispatched |
|-------------|-------------|-------------------|
| `/healthy-lifestyle/*` | HIL (Healthy Living) | Metadata, Editorial, Compliance, Accuracy, **Empty Tag** |
| Everything else | Standard medical | Metadata, Editorial, Compliance, Accuracy |

Routing uses LangGraph's **Send API** for parallel fan-out â€” all dispatched agents execute concurrently. The `dispatch_agents()` function reads the `routing_decision` from state (set by triage) and returns `Send(node_name, state)` for each selected agent.

## LLM-as-a-Judge

After all agents complete, the **judge node** (GPT-4o-mini) synthesizes findings into a recommendation:

- **approve** â€” content meets all standards
- **reject** â€” content has significant issues
- **needs_revision** â€” content has minor issues that should be addressed

The judge's recommendation and confidence level are shown to the human reviewer alongside the detailed agent findings, helping inform the final HITL decision.

## Observability (LangSmith)

LangSmith tracing is enabled by default. Each pipeline run is correlated to its validation via `run_id=validation_id`:

- **Per-agent tags**: Each LLM call is tagged with the agent name (e.g., `editorial-agent`, `accuracy-agent`)
- **Trace URLs**: Stored in the `trace_url` field of each validation after the HITL gate
- **Pipeline timeout**: 5-minute deadline per validation, 1-minute deadline per resume
- **Centralized LLM factory**: All agents use `create_agent_llm()` with `request_timeout=120s` per LLM call

> Set `LANGCHAIN_TRACING_V2=false` in `.env` to disable tracing.
